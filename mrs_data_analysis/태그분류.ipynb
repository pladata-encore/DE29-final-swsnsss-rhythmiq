{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xlrd\n",
    "pip install openpyxl\n",
    "pip install pandas\n",
    "pip install konlpy\n",
    "pip install customized_konlpy\n",
    "pip install matplotlib\n",
    "pip install emoji\n",
    "pip install soynlp\n",
    "pip install konlpy\n",
    "pip install torch transformers\n",
    "pip install sentence-transformers\n",
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install customized_konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from emoji import core\n",
    "import re\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from ckonlpy.tag import Twitter\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Mecab\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Hannanum\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['락', '추억', '회상', '잔잔한', '카페', '겨울', '연말', '크리스마스', '캐롤', '분위기', '댄스', '드라이브', '트로피컬', '일렉', '하우스', '힐링', '기분전환', '팝', '운동', '트렌드', '고백', '이별', '사랑', '짝사랑', '슬픔', '포크', '메탈', '스트레스', '새해', '여행', '우울', '감각', '힙합', '국내', '밤', '그루브', '새벽', '재즈', '가을', '감성', '설렘', '봄', '비', '혼자', '조용한', '맥주', '고민', '편안한', '어쿠스틱', '에너지', '달달', '남녀', '신나는', '미국', '랩소디', '클래식', '영화', '스윙', '상쾌', '아침', '휴식', '매장', '여름', '피트니스', '산책', '필라테스', '헬스', '다이어트', '러닝', '요가', '스포츠', '발라드', '위로', '옛날', '연주', '클럽', '오후', '주말', '나른함', '중국', '달', '유럽', '정화', '공기', '사무실', '알앤비', '불금', '차', '연애', '썸', '독서', '펍', '세련', '라운지', '퇴근', '한강', '랩', '섹시', '비트', '뉴에이지', '무드', '스웩', '꿀', '버스', '트렌디', '라디오', '벚꽃', '따뜻함', '포근함', '유튜브', '팝송', '자연', '프로그레시브', '바다', '시원', '아련', '치명', '강렬한', '여자', '아이돌', '인디뮤직', '호강', '인디밴드', '자장가', '추위', '일상', '잠', '몽환', '폭발', '페스티벌', '흥', '외힙', '기분', '키즈', '동화', '기타', '영국', '생각', '야경', '바캉스', '썸머', '휴가', '해변', '펑크', '고음', '명품', '연인', '아픔', '조깅', '출근', '소울', '가요', '여운', '인디음악', '힘든', '빠른', '퓨전', '해외', '저녁', '노동요', '디제이', '여름밤', '모던', '국외', '삶', '커피', '북카페', '그냥', '일요일', '시티', '나들이', '목요일', '걸그룹', '스타일', '파티', '인생', '베이스', '퓨처', '장마', '불면', '그리움', '외로움', '테크노', '가족', '연휴', '둠칫둠칫', '외국', '이태원', '리드미컬', '블루스', '커플', '후회', '부모님', '눈물', '미세먼지', '안녕', '휴일', '고속도로', '졸음', '운전', '독주곡', '피아노', '유니크', '바람', '샤워', '햇살', '컨트리', '공부', '백색소음', '숙면', '트로트', '동요', '감미로운', '시험', '집중', '명상', '센치', '드림팝', '실험', '여유', '쓸쓸함', '낭만', '올드팝', '데이트', '행복', '티타임', '끝', '정서', '아기', '발달', '남자', '하드록', '로큰롤', '잔잔함', '우아한', '미술관', '더위', '청량한', '노래방', '배경음악', '어린이', '마음', '테라', '태교', '중독', '최고', '피곤', '꿈', '집', '사이다', '발랄', '상큼', '텐션', '쇼핑', '책', '그룹', '좋아요', '방학', '달콤', '하늘', '광고', '뉴욕', '드럼', '환상', '음색', '월요병', '피크닉', '게임', '아메리카노', '가사', '맑음', '세대', '흑인', '침대', '공감', '꽃', '감상', '로맨틱', '레스토랑', '흔하지', '시크', '수능', '편집샵', '토닥토닥', '응원', '긍정', '수험생', '산뜻', '복고', '웨이브', '도시', '노을', '레트로', '가이드', '할로윈', '무더위', '한국', '멍', '일본', '유명한', '공원', '작업', '경쾌', '열대야', '휴양지', '여친', '두근두근', '자극', '드라마', '선선', '은혜', '워십', '찬양', '출발', '시작', '화이팅', '싱잉랩', '멜랑콜리', '감동', '임산부', '엄마', '부자', '차분한', '부드러운', '여성', '썸남썸녀', '생일', '축하', '원더풀', '지하철', '세계', '공허함', '가을비', '날씨', '컨템포러리', '프랑스', '이탈리아', '샹송', '방송', '국적', '축가', '결혼', '성인가요', '자전거', '홈트', '트레이닝', '아날로그', '오페라', '리메이크', '방', '바이올린', '신스팝', '느낌', '프로포즈', '프렌치', '인디팝', '선물', '취저', '힘나는', '편한', '졸업', '친구', '우정', '라이딩', '트랩', '쌀쌀한', '협주곡', '하루', '점심', '수고', '거리', '마무리', '다양한', '소풍', '솔로', '화이트데이', '발렌타인데이', '용기', '희망', '퇴폐', '춤', '낙엽', '즐거운', '이야기', '우주', '명절', '브라질', '보사노바', '예쁜', '매력', '오케스트라', '기억', '우산', '첫사랑', '이불', '회식', '설날', '추석', '고독', '감수성', '금요일', '들썩들썩', '회사', '분노', '웅장', '깊은', '월요일', '멘탈', '고급', '활기찬', '재생', '호주', '예배', '축제', '술', '서울', '질주', '파워', '케이팝', '사극', '시부야케이', '캠핑', '모임', '신비로운', '유치원', '낮잠', '기도', '와인', '삽입곡', '디스코', '패션', '마인드', '매일', '선율', '출퇴근', '남자친구', '외출', '얼터너티브', '대중', '넷플릭스', '갱스터', '호텔', '혼술', '어반', '브런치', '등교', '권태기', '크로스오버', '색다른', '편지', '봄비', '청량', '대박', '홀로', '치유', '싱숭생숭', '서정', '아름다운', '전통', '템포', '블랙뮤직', '불토', '천재', '향기', '소녀', '싱글', '심쿵', '당신', '익숙한', '계절', '야근', '세포', '트랜스', '직장인', '창작', '교향곡', '싱그러운', '청춘', '소름', '극복', '자존감', '독특한', '브릿팝', '충전', '자신감', '밥', '가볍게', '바운스', '사색', '요리', '덥스텝', '달리기', '공항', '학교', '애절한', '감정', '충만', '시절', '감사', '파리', '성악', '홈파티', '실내악', '버스킹', '과거', '싸이월드', '토요일', '지금', '동양', '안정', '병원', '뮤지컬', '옷가게', '준비', '사람', '매니아', '편안', '교회', '화창한', '아리랑', '레게', '올드스쿨', '애니메이션', '지브리', '심심', '영어', '런던', '해질녘', '평화', '개성', '홍대', '애절', '라틴', '이어폰', '기차', '기쁨', '디즈니', '신선한', '빈티지', '답답할', '구분', '젊음', '인디록', '소주', '과제', '통통', '비타민', '떼창', '섬세한', '열정', '스페인', '아빠', '지휘자', '살랑살랑', '향수', '비행기', '걷기', '특별한', '전환', '바이브', '시상식', '아일랜드', '아이', '심야', '센스', '라떼', '미련', '소나기', '가슴', '미디엄템포', '촉촉한', '어워드', '세상', '매혹', '헤비메탈', '대장', '멋진', '찬송가', '통기타', '핑크', '전설', '귀여운', '음식', '테라스', '현대', '참이슬', '새로운', '유산소', '바로크', '청소', '강아지', '몽롱', '늦가을', '숍', '달빛', '강남', '만남', '국악', '뿜뿜', '첼로', '괜찮아', '탈출', '만화', '자유', '스피닝', '거장', '야한', '포크록', '상처', '고요한', '보헤미안', '고전', '제이팝', '몽글몽글', '울적', '처방전', '짜증', '동심', '차가운', '아련함', '제주도', '그대', '사이키델릭', '예능', '간지', '학창시절', '반려동물', '네오소울', '기다림', '칵테일', '슬로우', '숨', '워킹', '업무', '스타벅스', '추모', '보석같은', '탱고', '단풍', '오디션', '트릭']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('data/카운터6.xlsx')\n",
    "tag_list = df['Tag'].dropna().tolist()\n",
    "\n",
    "print(tag_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# SBERT 모델 로드\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "# Okt 형태소 분석기\n",
    "tokenizer = Twitter()\n",
    "tokenizer.add_dictionary(tag_list, 'Noun')\n",
    "tokenizer.add_dictionary([\"플레이리스트\", \"집중력\", \"릴렉스\", \"고즈넉\"], 'Noun')\n",
    "# 미리 정해진 키워드의 BERT 임베딩 계산\n",
    "predefined_embeddings = {kw: model.encode(kw) for kw in tag_list}\n",
    "\n",
    "def extract_keywords(sentence, stopwords):\n",
    "    # 형태소 분석\n",
    "    sentence = core.replace_emoji(sentence, replace=\"\")\n",
    "    sentence = re.sub(\"[^ㄱ-ㅎ ㅏ-ㅣ가-힣 1-9]\", \"\", sentence)  # 정규 표현식 수행\n",
    "    sentence = re.sub('^ +', \"\", sentence)  # 공백은 empty 값으로 변경\n",
    "    tokenized_sentence = tokenizer.pos(sentence)\n",
    "\n",
    "    # 명사, 동사, 형용사 추출\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word[0] in stopwords]  # 불용어 제거\n",
    "    print(stopwords_removed_sentence)\n",
    "    keywords = [word for word, pos in stopwords_removed_sentence if pos in ['Noun', 'Adjective']]\n",
    "\n",
    "    return keywords\n",
    "\n",
    "def map_to_predefined_keywords(extracted_keywords):\n",
    "    mapped_keywords = []\n",
    "    for keyword in extracted_keywords:\n",
    "        keyword_embedding = model.encode(keyword)\n",
    "        similarities = {kw: cosine_similarity([keyword_embedding], [emb]).item() for kw, emb in predefined_embeddings.items()}\n",
    "        mapped_keyword = max(similarities, key=similarities.get)\n",
    "        mapped_keywords.append(mapped_keyword)\n",
    "    return mapped_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\n",
    "    \"이\", \"가\", \"은\", \"는\", \"을\", \"를\", \"의\", \"에\", \"에서\", \"와\", \"과\", \"도\", \"로\", \"으로\", \"하고\",\n",
    "    \"나\", \"다\", \"라\", \"의거\", \"에게\", \"뿐\", \"만\", \"조차\", \"까지\", \"에서부터\", \"으로부터\", \"까지만\",\n",
    "    \"그리고\", \"그러나\", \"하지만\", \"그렇지만\", \"그래서\", \"그러므로\", \"따라서\", \"그렇기 때문에\",\n",
    "    \"만약\", \"만일\", \"비록\", \"뿐만 아니라\", \"혹은\", \"또는\", \"만약에\", \"하여\", \"나\", \"너\", \"그\",\n",
    "    \"그녀\", \"저\", \"이\", \"그\", \"저\", \"우리\", \"너희\", \"그들\", \"것\", \"데\", \"수\", \"사람\", \"경우\",\n",
    "    \"때\", \"아주\", \"매우\", \"너무\", \"더\", \"가장\", \"거의\", \"약간\", \"조금\", \"상당히\", \"정말\",\n",
    "    \"진짜\", \"참\", \"자주\", \"항상\", \"또\", \"다시\", \"언제나\", \"이미\", \"아직\", \"곧\", \"방금\", \"지금\",\n",
    "    \"현재\", \"일단\", \"당장\", \"즉시\", \"곧바로\", \"이것\", \"저것\", \"그것\", \"여기\", \"저기\", \"거기\", \"플레이리스트\",\n",
    "    \"노래\", \"곡\", \"듣기\", \"좋은\", \"어울리는\", \"할\", \"때\", \"듣는\", \"했을\", \"지고\", \"음악\", \"나올\", \"트는\", \"추천\", \"찬\", \"면서\",\n",
    "    \"앞\", \"고픈\", \"운\", \"시간\", \"가득\", \"선율\", \"여주\", \"높\", \"뮤직\", \"충만\", \"날\", \"위\", \"히트\",\"모음\",\n",
    "    \"후\", \"업\", \"필요\", \"순간\", \"후의\", \"타임\", \"멜로디\", \"속\", \"기분\", \"여\", \"명곡\", \"물씬\", \"적\", \"온\", \"소리\", \"트랙\", \"취향\", \"저격\", \"송\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('드라이브', 'Noun'), ('한', 'Josa'), ('로드', 'Noun'), ('트립', 'Noun')]\n",
      "Extracted Keywords: ['드라이브', '로드', '트립']\n",
      "Mapped Keywords: ['드라이브', '트랩', '최고']\n"
     ]
    }
   ],
   "source": [
    "# 입력 문장\n",
    "sentence = \"드라이브를 위한 로드 트립 송\"\n",
    "\n",
    "# 키워드 추출\n",
    "extracted_keywords = extract_keywords(sentence, stopwords)\n",
    "print(f\"Extracted Keywords: {extracted_keywords}\")\n",
    "\n",
    "# 유사 키워드 매핑\n",
    "mapped_keywords = map_to_predefined_keywords(extracted_keywords)\n",
    "print(f\"Mapped Keywords: {mapped_keywords}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
